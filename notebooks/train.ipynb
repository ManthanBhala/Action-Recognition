{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0627 10:56:36.145665 139830347638528 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import hashlib\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import keras\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, LSTM, CuDNNLSTM, Dropout, BatchNormalization, Masking, TimeDistributed,Bidirectional \n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "from sklearn import datasets, metrics\n",
    "import shutil\n",
    "from keras import initializers\n",
    "from keras.models import load_model, Sequential\n",
    "import pickle\n",
    "import random \n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MobileNetV2()\n",
    "#model = keras.applications.mobilenet_v2.MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining hyperparameters\n",
    "\n",
    "train_dir = \"human_seg_train_frames\"\n",
    "val_dir = \"human_seg_val_frames\"\n",
    "test_dir = \"human_seg_test_frames\"\n",
    "train_bottlenecks_dir = \"human_seg_train_bottlenecks\"\n",
    "val_bottlenecks_dir = \"human_seg_val_bottlenecks\"\n",
    "test_bottlenecks_dir = \"human_seg_test_bottlenecks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_folder_exists(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_base_model_for_bottlenecks(show_model_summary = False):\n",
    "    #Arguments     : show_model_summary--> whether to show model summary/layers\n",
    "    #Returns       : models-->mobilenetV2 with its last layer being 'global_average_pooling2d_1'\n",
    "    \n",
    "    model = MobileNetV2()\n",
    "    if show_model_summary:\n",
    "        model.summary()\n",
    "    base_model = Model(inputs=model.input, outputs=model.get_layer('global_average_pooling2d_1').output)\n",
    "    print(\"Base_model_loaded 100 percent\")\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_save_bottlenecks(model, image_dir, bottlenecks_dir):\n",
    "    #Arguments     : model-->model to create bottlenecks\n",
    "    #                image-dir--> path of directory where images are stored in class-wise folder\n",
    "    #                bottlenecks_dir--> path of directory where bottlenecks will be \n",
    "    #                                   stored in text file in class-wise folder.\n",
    "    #Returns       : bottlenecks_shape\n",
    "    #Description   : creates and saves the bottleneck for images using mobilenetV2\n",
    "    \n",
    "    ensure_folder_exists(bottlenecks_dir)\n",
    "    for count,filename in enumerate(Path(image_dir).glob('**/*.jpeg')):\n",
    "        file_path = str(filename)\n",
    "        target_path = bottlenecks_dir + file_path[file_path.find(\"/\"):-5]\n",
    "        ensure_folder_exists(os.path.split(target_path)[0])\n",
    "        img = image.load_img(file_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        features = model.predict(x)\n",
    "        bottlenecks_shape = len(features[0])\n",
    "        with open(target_path + '.txt', 'w') as f:\n",
    "            for item in features[0]:\n",
    "                f.write(\"%f \" % item)\n",
    "        if(count%2000==0):\n",
    "            print(\"Bottlenecks Created : \"+str(count))\n",
    "    print(\"All bottlenecks saved\")\n",
    "    return bottlenecks_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_bottlenecks_to_xy_numpy_array(bottlenecks_shape,x,y):\n",
    "    #Description   : preprocess bottlenecks to store them in numpy array\n",
    "    \n",
    "    x_temp=[]\n",
    "    new_x=np.ndarray((len(x),bottlenecks_shape),np.float32)\n",
    "    new_y=np.ndarray((len(y)),np.int32)\n",
    "    x_temp=x[0].split()\n",
    "    for i,s in enumerate(x):\n",
    "        x_temp=s.split()\n",
    "        for j in range(len(x_temp)):\n",
    "            new_x[i,j]=float((x_temp[j]))\n",
    "        new_y[i]=int(y[i])\n",
    "    return new_x,new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_saved_bottlenecks(bottlenecks_dir,bottlenecks_shape=1280):\n",
    "    #Arguments     : bottlenecks_dir--> path of directory where bottlenecks will be \n",
    "    #                                   stored in text file in class-wise folder.\n",
    "    #Returns       : \n",
    "    #Description   : X-->bottlenecks of all frames\n",
    "    #                Y-->class of all frames in number form\n",
    "    #                class_names-->List containing class names\n",
    "    #                num_classes-->Number of total classes\n",
    "    #                file_names-->list of names of bottlenecks file\n",
    "    \n",
    "    features=sklearn.datasets.load_files(bottlenecks_dir) #check its's documentation to understand what it's returning\n",
    "    x=features.data\n",
    "    y=features.target\n",
    "    class_names=np.asarray(features.target_names)\n",
    "    num_classes=len(class_names)\n",
    "    X,Y=preprocess_bottlenecks_to_xy_numpy_array(bottlenecks_shape,x,y)\n",
    "    file_names_with_dir=np.asarray(features.filenames)\n",
    "    file_names=[]\n",
    "    for s in file_names_with_dir:\n",
    "        name=s.split('/')[2]\n",
    "        file_names.append(name)\n",
    "    return X,Y,class_names,num_classes,file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pickle_file(bottlenecks_dir,output_file):\n",
    "    #Arguments     : bottlenecks_dir--> path of directory where bottlenecks will be \n",
    "    #                                   stored in text file in class-wise folder.\n",
    "    #                output_file--> path where pickle file need to be stored\n",
    "    #Returns       : None\n",
    "    #Description   : Loading bottlenecks from txt file again and again takes too much time.\n",
    "    #                That's why we store all bottleneck vallues in pickle file that can be loaded easily\n",
    "    \n",
    "    X,Y,class_names,num_classes,file_names=get_xy_saved_bottlenecks(bottlenecks_dir)\n",
    "    cache={\n",
    "        'features':X,\n",
    "        'class_value':Y,\n",
    "        'class_names':class_names,\n",
    "        'file_names':file_names,\n",
    "        'num_classes':num_classes\n",
    "    }\n",
    "    out_file=output_file\n",
    "    with open(out_file, 'wb') as fout:\n",
    "        pickle.dump(cache, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=get_pretrained_base_model_for_bottlenecks(show_model_summary = False)\n",
    "bottlenecks_shape=compute_and_save_bottlenecks(base_model, train_dir, train_bottlenecks_dir)\n",
    "bottlenecks_shape=compute_and_save_bottlenecks(base_model, val_dir, val_bottlenecks_dir)\n",
    "bottlenecks_shape=compute_and_save_bottlenecks(base_model, test_dir, test_bottlenecks_dir)\n",
    "make_pickle_file(train_bottlenecks_dir,output_file=\"human_seg_train_features.pkl\")\n",
    "make_pickle_file(val_bottlenecks_dir,output_file=\"human_seg_val_features.pkl\")\n",
    "make_pickle_file(test_bottlenecks_dir,output_file=\"human_seg_test_features.pkl\")\n",
    "print(\"bottlenecks_shape=\"+str(bottlenecks_shape))\n",
    "remove_ipynb_checkpoint_files(bottlenecks_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll create and train RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_pickle_file(file_name):\n",
    "    #Arguments     : pickle file path\n",
    "    #Returns       : features, Y, class_names, file_names, num_classes\n",
    "    #Description   : Loads data from pickle file\n",
    "    \n",
    "    pickle_in = open(file_name,\"rb\")\n",
    "    cache = pickle.load(pickle_in)\n",
    "    features=cache['features']\n",
    "    Y=cache['class_value']\n",
    "    class_names=cache['class_names']\n",
    "    file_names=np.asarray(cache['file_names'])\n",
    "    num_classes=cache['num_classes']\n",
    "    print(\"Data loaded from pickle file\")\n",
    "    return features, Y, class_names, file_names, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_for_rnn_input(features,Y,file_names):\n",
    "    #Arguments     : features--> x for rnn input\n",
    "    #                Y,file_names\n",
    "    #Description   : as all frames are in random order but we need to give rnn model frames\n",
    "    #                in video wise order. So, this function clubs all frames of particular video \n",
    "    #                together and then sorts them according to their filenames so that they can be\n",
    "    #                given as input to rnn in series.\n",
    "    \n",
    "    zipped=zip(file_names,Y,features)\n",
    "    zipped=sorted(zipped,key = lambda x: x[0])\n",
    "    total_frames=Y.shape[0]\n",
    "    feature_size=features.shape[1]\n",
    "    rnn_X=[]\n",
    "    rnn_Y=[]    \n",
    "    rnn_file_names=[]\n",
    "\n",
    "    start=0\n",
    "    end=0\n",
    "    current_name=\"\"\n",
    "    last_name=\"\"\n",
    "    while end<total_frames:\n",
    "        if last_name==\"\":\n",
    "            temp_name=zipped[0][0]\n",
    "            last_name=temp_name[:-len(temp_name.split(\"_\")[-1])] \n",
    "            current_name=temp_name[:-len(temp_name.split(\"_\")[-1])] \n",
    "        while current_name==last_name:\n",
    "            end+=1\n",
    "            if end>=total_frames:\n",
    "                break\n",
    "            current_name=zipped[end][0][:-len(zipped[end][0].split(\"_\")[-1])] \n",
    "        current_zip=zipped[start:end]\n",
    "        current_zip=sorted(current_zip,key = lambda x : int((x[0].split('_')[-1]).split('.')[0]))\n",
    "        rnn_X.append(list(zip(*current_zip))[2])\n",
    "        rnn_Y.append((list(zip(*current_zip))[1])[0])\n",
    "        rnn_file_names.append(list(zip(*current_zip))[0])\n",
    "        last_name=current_name\n",
    "        start=end\n",
    "    rnn_X=np.asarray(rnn_X)\n",
    "    rnn_Y=np.asarray(rnn_Y)\n",
    "    rnn_file_names=np.asarray(rnn_file_names)\n",
    "    return rnn_X,rnn_Y,rnn_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(x,y,file_name):\n",
    "    #Description   : shuffles the data video-wise ( not frame-wise)\n",
    "    \n",
    "    np.random.seed(25)  \n",
    "    random=np.arange(x.shape[0])\n",
    "    np.random.shuffle(random)\n",
    "    x=x[random]\n",
    "    y=y[random]\n",
    "    file_name=file_name[random]\n",
    "    del random\n",
    "    return x,y,file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from pickle file\n",
      "Data loaded from pickle file\n",
      "Data loaded from pickle file\n"
     ]
    }
   ],
   "source": [
    "#Getting data from pickle file\n",
    "features,Y,class_names,file_names,num_classes=get_data_from_pickle_file(\n",
    "                                              file_name=\"human_seg_train_features.pkl\")\n",
    "val_features,val_Y,val_class_names,val_file_names,val_num_classes=get_data_from_pickle_file(\n",
    "                                                                  file_name=\"human_seg_val_features.pkl\")\n",
    "test_features,test_Y,test_class_names,test_file_names,test_num_classes=get_data_from_pickle_file(\n",
    "                                                                  file_name=\"human_seg_test_features.pkl\")\n",
    "#preprocess\n",
    "rnn_X,rnn_Y,rnn_file_names=preprocess_data_for_rnn_input(features,Y,file_names)\n",
    "val_rnn_X,val_rnn_Y,val_rnn_file_names=preprocess_data_for_rnn_input(val_features,val_Y,val_file_names)\n",
    "test_rnn_X,test_rnn_Y,test_rnn_file_names=preprocess_data_for_rnn_input(test_features,test_Y,test_file_names)\n",
    "#shuffle\n",
    "rnn_X,rnn_Y,file_names=shuffle_data(rnn_X,rnn_Y,file_names)\n",
    "#val_rnn_X,val_rnn_Y,val_file_names=shuffle_data(val_rnn_X,val_rnn_Y,val_file_names)\n",
    "#test_rnn_X,test_rnn_Y,test_file_names=shuffle_data(test_rnn_X,test_rnn_Y,test_file_names)\n",
    "#To categorical classes\n",
    "val_temp_y=val_rnn_Y\n",
    "test_temp_y=test_rnn_Y\n",
    "rnn_Y=to_categorical(rnn_Y)\n",
    "val_rnn_Y=to_categorical(val_rnn_Y)\n",
    "test_rnn_Y=to_categorical(test_rnn_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for epoch=18, approx accuracy stable=45\n",
    "def lstm_model_1(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0.0,input_shape=(None,1280)))\n",
    "    model.add(TimeDistributed(Dense(128)))\n",
    "    model.add(LSTM(256,dropout=0.5)) \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for epoch=18, approx accuracy stable>=50\n",
    "def lstm_model_2(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0.0,input_shape=(None,1280)))\n",
    "    model.add(Bidirectional(LSTM(512,dropout=0.5)))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for epoch=18, approx accuracy stable>=50\n",
    "def lstm_model(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0.0,input_shape=(None,1280)))\n",
    "    model.add(Bidirectional(LSTM(512,dropout=0.5,return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(256,dropout=0.5)))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_for_validation(x,y,model,keyword):\n",
    "    correct=0\n",
    "    total_loss=0\n",
    "    y_pred=[]\n",
    "    for i in range(x.shape[0]):\n",
    "        batch_X = sequence.pad_sequences(x[i], dtype='float32', padding='pre', value=0.0)\n",
    "        batch_X=np.reshape(batch_X,(1,batch_X.shape[0],batch_X.shape[1]))\n",
    "        batch_Y=np.reshape(y[i,:],(1,y.shape[1]))\n",
    "        y_pred.append(model.predict_on_batch(batch_X))\n",
    "        loss,acc=model.evaluate(batch_X, batch_Y,verbose=0)\n",
    "        total_loss+=loss\n",
    "        if int(acc)==1:\n",
    "            correct+=1\n",
    "    total_loss/=x.shape[0]\n",
    "    percent=correct*100/x.shape[0]\n",
    "    if keyword==\"val\":\n",
    "        print(\"Validation Accuracy = \",str(percent),\" %\",\"     Validation Loss = \",str(total_loss))\n",
    "    else:\n",
    "        print(\"      Test Accuracy = \",str(percent),\" %\",\"           Test Loss = \",str(total_loss))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 10:56:52.910196 139830347638528 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 10:56:54.659363 139830347638528 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model(num_classes=16)\n",
    "model.compile(loss='categorical_crossentropy',optimizer ='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch--> 0\n",
      "Train Loss =  0.1653456191221873       Train Accuracy =  0.9430338541666666\n",
      "Validation Accuracy =  78.125  %      Validation Loss =  1.017340524912015\n",
      "      Test Accuracy =  65.625  %            Test Loss =  1.2467592750572933\n"
     ]
    }
   ],
   "source": [
    "epochs=1\n",
    "batch_size=128\n",
    "total_videos=rnn_X.shape[0]\n",
    "for i in range(epochs):\n",
    "    start=0\n",
    "    end=batch_size\n",
    "    count=0\n",
    "    loss=0\n",
    "    accuracy=0\n",
    "    while(end<=total_videos):\n",
    "        batch_X=rnn_X[start:end]\n",
    "        batch_Y=rnn_Y[start:end,:]\n",
    "        batch_X = sequence.pad_sequences(batch_X, dtype='float32', padding='pre', value=0.0)\n",
    "        cur_loss,cur_accuracy=model.train_on_batch(batch_X,batch_Y)\n",
    "        loss+=cur_loss\n",
    "        accuracy+=cur_accuracy\n",
    "        start=end\n",
    "        end+=batch_size\n",
    "        count+=1\n",
    "    batch_X=rnn_X[start:]\n",
    "    batch_Y=rnn_Y[start:,:]\n",
    "    batch_X = sequence.pad_sequences(batch_X, dtype='float32', padding='pre', value=0.0)\n",
    "    \n",
    "    cur_loss,cur_accuracy=model.train_on_batch(batch_X,batch_Y)\n",
    "    #loss+=cur_loss\n",
    "    #accuracy+=cur_accuracy\n",
    "    #count+=1\n",
    "    loss/=count\n",
    "    accuracy/=count\n",
    "    print(\"Epoch-->\",str(i))\n",
    "    print(\"Train Loss = \",str(loss),\"      Train Accuracy = \",str(accuracy))\n",
    "    evaluate_for_validation(val_rnn_X,val_rnn_Y,model,keyword=\"val\")\n",
    "    evaluate_for_validation(test_rnn_X,test_rnn_Y,model,keyword=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"human_seg_rnn_mask_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 10:57:11.794563 139830347638528 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"human_seg_rnn_mask_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy =  78.125  %      Validation Loss =  1.017340524912015\n"
     ]
    }
   ],
   "source": [
    "y_pred=evaluate_for_validation(val_rnn_X,val_rnn_Y,model,keyword=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99976593 0.46000385 0.864835   0.93600845 0.9996493  0.9331826\n",
      " 0.5098977  0.5469188  0.97864836 0.9914725  0.97451425 0.87044996\n",
      " 0.77866656 0.5944352  0.67526996 0.9979905  0.99888057 0.9989371\n",
      " 0.9972905  0.9316171  0.99775547 0.99714595 0.8912208  0.86364\n",
      " 0.65579826 0.84527004 0.9976956  0.99947363 0.9939129  0.83029974\n",
      " 0.88435155 0.9874193 ]\n",
      "['ABOVE' 'ACCIDENT' 'ADVISE_or_INFLUENCE' 'AFTERNOON' 'AGAIN' 'ALLIGATOR'\n",
      " 'ANSWER' 'A_LOT' 'BECAME' 'COME_HERE' 'EXCEED' 'GENERATION' 'LESS_THAN'\n",
      " 'OF' 'THREAT' 'TOTAL']\n",
      "ABOVE ------------> ABOVE\n",
      "ABOVE ------------> ABOVE\n",
      "TOTAL ------------> ACCIDENT\n",
      "TOTAL ------------> TOTAL\n",
      "OF ------------> OF\n",
      "OF ------------> OF\n",
      "ANSWER ------------> ANSWER\n",
      "ANSWER ------------> ANSWER\n",
      "COME_HERE ------------> COME_HERE\n",
      "COME_HERE ------------> COME_HERE\n",
      "THREAT ------------> THREAT\n",
      "THREAT ------------> THREAT\n",
      "ALLIGATOR ------------> ALLIGATOR\n",
      "ALLIGATOR ------------> ALLIGATOR\n",
      "GENERATION ------------> ADVISE_or_INFLUENCE\n",
      "GENERATION ------------> GENERATION\n",
      "LESS_THAN ------------> LESS_THAN\n",
      "LESS_THAN ------------> LESS_THAN\n",
      "ACCIDENT ------------> ACCIDENT\n",
      "ACCIDENT ------------> ACCIDENT\n",
      "BECAME ------------> BECAME\n",
      "BECAME ------------> BECAME\n",
      "AFTERNOON ------------> GENERATION\n",
      "AFTERNOON ------------> GENERATION\n",
      "AGAIN ------------> AGAIN\n",
      "AGAIN ------------> TOTAL\n",
      "A_LOT ------------> A_LOT\n",
      "A_LOT ------------> A_LOT\n",
      "EXCEED ------------> EXCEED\n",
      "EXCEED ------------> EXCEED\n",
      "ADVISE_or_INFLUENCE ------------> GENERATION\n",
      "ADVISE_or_INFLUENCE ------------> GENERATION\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=np.asarray(y_pred)\n",
    "y_pred=np.reshape(y_pred,(32,16))\n",
    "print(y_pred.max(axis=-1))\n",
    "print(class_names)\n",
    "y_classes = y_pred.argmax(axis=-1)\n",
    "zipped1=list(zip(val_temp_y,y_classes))\n",
    "for i in range(len(zipped1)):\n",
    "    print(class_names[int(zipped1[i][0])],\"------------>\",class_names[int(zipped1[i][1])])\n",
    "matrix = metrics.confusion_matrix(val_rnn_Y.argmax(axis=-1), y_pred.argmax(axis=-1))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Test Accuracy =  65.625  %            Test Loss =  1.2467592750572933\n",
      "[0.51499397 0.8116202  0.6549879  0.9762674  0.6230682  0.69542474\n",
      " 0.99947053 0.70946366 0.99055547 0.99984336 0.997203   0.90080386\n",
      " 0.9992248  0.9777108  0.9847141  0.999879   0.9866209  0.99681205\n",
      " 0.9611812  0.99702317 0.72886205 0.72410405 0.53693587 0.87503856\n",
      " 0.99342597 0.998727   0.999998   0.9999175  0.9876281  0.9997695\n",
      " 0.9614989  0.8279593 ]\n",
      "['ABOVE' 'ACCIDENT' 'ADVISE_or_INFLUENCE' 'AFTERNOON' 'AGAIN' 'ALLIGATOR'\n",
      " 'ANSWER' 'A_LOT' 'BECAME' 'COME_HERE' 'EXCEED' 'GENERATION' 'LESS_THAN'\n",
      " 'OF' 'THREAT' 'TOTAL']\n",
      "ABOVE ------------> ABOVE\n",
      "ABOVE ------------> ABOVE\n",
      "TOTAL ------------> TOTAL\n",
      "TOTAL ------------> ACCIDENT\n",
      "OF ------------> COME_HERE\n",
      "OF ------------> ABOVE\n",
      "ANSWER ------------> ANSWER\n",
      "ANSWER ------------> GENERATION\n",
      "COME_HERE ------------> ACCIDENT\n",
      "COME_HERE ------------> COME_HERE\n",
      "THREAT ------------> THREAT\n",
      "THREAT ------------> GENERATION\n",
      "ALLIGATOR ------------> AFTERNOON\n",
      "ALLIGATOR ------------> GENERATION\n",
      "GENERATION ------------> GENERATION\n",
      "GENERATION ------------> GENERATION\n",
      "LESS_THAN ------------> LESS_THAN\n",
      "LESS_THAN ------------> LESS_THAN\n",
      "ACCIDENT ------------> ACCIDENT\n",
      "ACCIDENT ------------> ACCIDENT\n",
      "BECAME ------------> BECAME\n",
      "BECAME ------------> BECAME\n",
      "AFTERNOON ------------> AFTERNOON\n",
      "AFTERNOON ------------> THREAT\n",
      "AGAIN ------------> AGAIN\n",
      "AGAIN ------------> AGAIN\n",
      "A_LOT ------------> A_LOT\n",
      "A_LOT ------------> A_LOT\n",
      "EXCEED ------------> EXCEED\n",
      "EXCEED ------------> EXCEED\n",
      "ADVISE_or_INFLUENCE ------------> GENERATION\n",
      "ADVISE_or_INFLUENCE ------------> GENERATION\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=evaluate_for_validation(test_rnn_X,test_rnn_Y,model,keyword=\"test\")\n",
    "y_pred=np.asarray(y_pred)\n",
    "y_pred=np.reshape(y_pred,(32,16))\n",
    "print(y_pred.max(axis=-1))\n",
    "print(class_names)\n",
    "y_classes = y_pred.argmax(axis=-1)\n",
    "zipped1=list(zip(test_temp_y,y_classes))\n",
    "for i in range(len(zipped1)):\n",
    "    print(class_names[int(zipped1[i][0])],\"------------>\",class_names[int(zipped1[i][1])])\n",
    "matrix = metrics.confusion_matrix(val_rnn_Y.argmax(axis=-1), y_pred.argmax(axis=-1))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
